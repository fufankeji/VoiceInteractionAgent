"""Qwen3 ASR Flash Realtime - å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡ (WebSocket API)"""
import asyncio
import base64
import json
import logging
from typing import Optional

import websockets

from app.core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()




async def transcribe_audio_stream(
    audio_data: bytes,
    format: str = "pcm",
    sample_rate: int = 16000,
    language: str = "zh",
    enable_vad: bool = False,
) -> str:
    """
    ä½¿ç”¨ Qwen3 ASR Flash Realtime è¯†åˆ«éŸ³é¢‘æµ (WebSocket API)
    
    Args:
        audio_data: PCM éŸ³é¢‘æ•°æ® (bytes)
        format: éŸ³é¢‘æ ¼å¼ (pcm, wav, opus ç­‰)
        sample_rate: é‡‡æ ·ç‡
        language: è¯­è¨€ (zh, en, etc.)
        enable_vad: æ˜¯å¦å¯ç”¨æœåŠ¡ç«¯ VAD
    
    Returns:
        è¯†åˆ«çš„å®Œæ•´æ–‡æœ¬
    """
    logger.info(
        f"[ASR-Realtime] ï¿½ï¸ å¼€å§‹è¯†åˆ«éŸ³é¢‘æµ "
        f"(æ ¼å¼={format}, é‡‡æ ·ç‡={sample_rate}Hz, å¤§å°={len(audio_data)} bytes, VAD={enable_vad})"
    )
    
    # æ„å»º WebSocket URL
    model = settings.default_asr_model
    base_url = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime"
    ws_url = f"{base_url}?model={model}"
    
    # æ„å»ºè¯·æ±‚å¤´
    headers = {
        "Authorization": f"Bearer {settings.dashscope_api_key}",
        "OpenAI-Beta": "realtime=v1"
    }
    
    final_text = ""
    error_msg = None
    
    try:
        # è¿æ¥ WebSocket
        logger.debug(f"[ASR-Realtime] ğŸ”Œ è¿æ¥åˆ°: {ws_url}")
        async with websockets.connect(
            ws_url,
            extra_headers=headers,
            ping_interval=None,
        ) as websocket:
            logger.info("[ASR-Realtime] âœ… WebSocket è¿æ¥æˆåŠŸ")
            
            # 1. å‘é€ session.update äº‹ä»¶
            session_config = {
                "event_id": f"event_{int(asyncio.get_event_loop().time() * 1000)}",
                "type": "session.update",
                "session": {
                    "modalities": ["text"],
                    "input_audio_format": format,
                    "sample_rate": sample_rate,
                    "input_audio_transcription": {
                        "language": language,
                    }
                }
            }
            
            # å¦‚æœå¯ç”¨ VADï¼Œæ·»åŠ  turn_detection
            if enable_vad:
                session_config["session"]["turn_detection"] = {
                    "type": "server_vad",
                    "threshold": 0.2,
                    "silence_duration_ms": 800
                }
            else:
                session_config["session"]["turn_detection"] = None
            
            logger.debug(f"[ASR-Realtime] ï¿½ å‘é€é…ç½®: {json.dumps(session_config, ensure_ascii=False)}")
            await websocket.send(json.dumps(session_config))
            
            # ç­‰å¾…é…ç½®ç¡®è®¤
            response = await websocket.recv()
            logger.debug(f"[ASR-Realtime] ï¿½ é…ç½®å“åº”: {response}")
            
            # 2. å‘é€éŸ³é¢‘æ•°æ®
            # å°†éŸ³é¢‘æ•°æ®åˆ†å—å‘é€ (æ¯æ¬¡ 3200 å­—èŠ‚ï¼Œæ¨¡æ‹Ÿå®æ—¶æµ)
            chunk_size = 3200
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                encoded_chunk = base64.b64encode(chunk).decode('utf-8')
                
                audio_event = {
                    "event_id": f"event_{int(asyncio.get_event_loop().time() * 1000)}",
                    "type": "input_audio_buffer.append",
                    "audio": encoded_chunk
                }
                
                await websocket.send(json.dumps(audio_event))
                logger.debug(f"[ASR-Realtime] ï¿½ å‘é€éŸ³é¢‘å—: {len(chunk)} bytes")
                
                # æ¨¡æ‹Ÿå®æ—¶å‘é€ (10ms é—´éš”)
                await asyncio.sleep(0.01)
            
            # 3. å¦‚æœæœªå¯ç”¨ VADï¼Œå‘é€ commit äº‹ä»¶
            if not enable_vad:
                commit_event = {
                    "event_id": f"event_{int(asyncio.get_event_loop().time() * 1000)}",
                    "type": "input_audio_buffer.commit"
                }
                logger.debug("[ASR-Realtime] ğŸ“¤ å‘é€ commit äº‹ä»¶")
                await websocket.send(json.dumps(commit_event))
            
            # 4. æ¥æ”¶è¯†åˆ«ç»“æœ
            logger.info("[ASR-Realtime] ï¿½ ç­‰å¾…è¯†åˆ«ç»“æœ...")
            timeout = 30
            start_time = asyncio.get_event_loop().time()
            
            while asyncio.get_event_loop().time() - start_time < timeout:
                try:
                    # è®¾ç½®çŸ­è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
                    response = await asyncio.wait_for(websocket.recv(), timeout=1.0)
                    
                    try:
                        event = json.loads(response)
                        event_type = event.get("type", "")
                        
                        logger.debug(
                            f"[ASR-Realtime] ï¿½ æ”¶åˆ°äº‹ä»¶: {event_type} | "
                            f"{json.dumps(event, ensure_ascii=False)}"
                        )
                        
                        # è¯†åˆ«è½¬å½•äº‹ä»¶
                        if event_type == "conversation.item.input_audio_transcription.completed":
                            transcript = event.get("transcript", "")
                            if transcript:
                                final_text = transcript
                                logger.info(f"[ASR-Realtime] ğŸ“ è¯†åˆ«æ–‡æœ¬: {transcript}")
                                # æ”¶åˆ°å®Œæ•´è¯†åˆ«ç»“æœï¼Œç«‹å³é€€å‡º
                                break
                        
                        # é”™è¯¯äº‹ä»¶
                        elif event_type == "error":
                            error_data = event.get("error", {})
                            error_msg = error_data.get("message", "æœªçŸ¥é”™è¯¯")
                            logger.error(f"[ASR-Realtime] âŒ æœåŠ¡ç«¯é”™è¯¯: {error_msg}")
                            break
                        
                        # ä¼šè¯ç»“æŸ
                        elif event_type in ["conversation.item.input_audio_transcription.failed", "done"]:
                            logger.info("[ASR-Realtime] ğŸ è¯†åˆ«æµç¨‹ç»“æŸ")
                            break
                    
                    except json.JSONDecodeError:
                        logger.warning(f"[ASR-Realtime] âš ï¸ æ— æ³•è§£æå“åº”: {response}")
                
                except asyncio.TimeoutError:
                    # è¶…æ—¶ä½†ç»§ç»­ç­‰å¾…
                    continue
                except websockets.exceptions.ConnectionClosed:
                    logger.info("[ASR-Realtime] ğŸ”Œ WebSocket è¿æ¥å·²å…³é—­")
                    break
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if asyncio.get_event_loop().time() - start_time >= timeout:
                logger.warning("[ASR-Realtime] â° è¯†åˆ«è¶…æ—¶")
    
    except Exception as e:
        logger.exception(f"[ASR-Realtime] âŒ WebSocket é€šä¿¡å¤±è´¥: {e}")
        raise RuntimeError(f"ASR è¯†åˆ«å¤±è´¥: {e}")
    
    # è¿”å›ç»“æœ
    if error_msg:
        raise RuntimeError(f"ASR é”™è¯¯: {error_msg}")
    
    if not final_text:
        logger.warning("[ASR-Realtime] âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
        return ""
    
    logger.info(f"[ASR-Realtime] âœ… è¯†åˆ«æˆåŠŸ: {final_text}")
    return final_text



async def transcribe_audio_base64(
    audio_b64: str,
    format: str = "pcm",
    sample_rate: int = 16000,
    language: str = "zh",
    enable_vad: bool = False,
) -> str:
    """
    è¯†åˆ« Base64 ç¼–ç çš„éŸ³é¢‘
    
    Args:
        audio_b64: Base64 ç¼–ç çš„éŸ³é¢‘æ•°æ®
        format: éŸ³é¢‘æ ¼å¼
        sample_rate: é‡‡æ ·ç‡
        language: è¯­è¨€
        enable_vad: æ˜¯å¦å¯ç”¨ VAD
    
    Returns:
        è¯†åˆ«çš„æ–‡æœ¬
    """
    audio_data = base64.b64decode(audio_b64)
    return await transcribe_audio_stream(
        audio_data=audio_data,
        format=format,
        sample_rate=sample_rate,
        language=language,
        enable_vad=enable_vad,
    )


# å…¼å®¹æ—§æ¥å£çš„ç®€åŒ–å‡½æ•°
async def recognize_speech(audio_data: bytes) -> str:
    """
    ç®€åŒ–çš„è¯­éŸ³è¯†åˆ«æ¥å£
    
    Args:
        audio_data: PCM16 éŸ³é¢‘æ•°æ® (16kHz, å•å£°é“)
    
    Returns:
        è¯†åˆ«çš„æ–‡æœ¬
    """
    return await transcribe_audio_stream(
        audio_data=audio_data,
        format="pcm",
        sample_rate=16000,
        language="zh",
        enable_vad=False,
    )

